# 実装計画書：AI採用候補者評価アプリ（テキスト入力版）

## 1. プロジェクト概要

### 1.1. 目的

採用担当者がWebアプリのテキストボックスに候補者情報を入力すると、Google Gemini APIを利用して定義済み基準に基づき自動評価を行い、結果（評価記号、理由、マッチ度スコア、所見）をダッシュボードに表示する。さらに、評価結果をCSV/Markdown形式でエクスポート可能にすることで、採用業務の効率化と評価の標準化を実現する。

### 1.2. スコープ

*   **主要機能:** テキスト入力、Gemini APIによる評価、マッチ度スコア計算、ダッシュボード表示（単一/累積）、CSV/Markdownエクスポート。
*   **対象範囲外:** DB永続化、ユーザー認証、プロンプト動的編集、ファイル直接インポート。

### 1.3. 採用技術スタック（想定）

*   **バックエンド:** Python + Flask (または FastAPI)
    *   主要ライブラリ: `google-generativeai`, `Flask`/`FastAPI`, `python-dotenv` (APIキー管理), `pandas` (CSV/データ処理), `markdown` (Markdown生成)
*   **フロントエンド:** React (または Vue.js / Svelte)
    *   主要ライブラリ: `axios` (API通信), (任意) UIライブラリ (Material UI, Chakra UI, Ant Design 등), (任意) 状態管理ライブラリ (Zustand, Redux Toolkit, Pinia)
*   **AI:** Google Gemini API (例: `gemini-pro`)
*   **バージョン管理:** Git / GitHub (または GitLab/Bitbucket)
*   **その他:** (任意) Dockerによるコンテナ化

## 2. 開発体制

*   本計画書は、1名〜少人数の開発者を想定。
    *   **役割:** フルスタック開発者 (バックエンド、フロントエンド、API連携、テスト担当)
    *   必要に応じて、特定のフェーズ（例: UIデザイン）で外部協力を検討。

## 3. 開発環境

*   **言語/フレームワーク:** Python 3.9+, Node.js 18+
*   **IDE:** VS Code, PyCharm など
*   **APIキー管理:** `.env`ファイルと`python-dotenv`ライブラリを使用し、環境変数経由でバックエンドに読み込ませる。`.env`ファイルはGit管理対象外とする。
*   **インフラ:** ローカル開発環境、(任意) Docker Desktop
*   **コミュニケーション:** (チームの場合) Slack, Teams など / (個人) GitHub Issues など

## 4. 実装スケジュール（フェーズ分け）

| フェーズ | 名称                           | 期間目安 | 主要タスク                                                                                                                                                                                             | 成果物                                                                 |
| :------- | :----------------------------- | :------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------- |
| 1        | 基盤構築とコア機能(BE)       | 3-5日    | プロジェクトセットアップ(BE), Gemini API連携実装, `/evaluate` API (テキスト受け取り、評価実行、スコア計算、単一JSON応答), 簡易テスト                                                                      | 動作する `/evaluate` API, Gemini連携モジュール, スコア計算モジュール |
| 2        | フロントエンド基本UIと連携     | 2-3日    | プロジェクトセットアップ(FE), テキスト入力エリア, 解析ボタン, `/evaluate` API呼び出し実装, 応答JSON表示, 基本的なエラー表示                                                                              | APIと疎通できる基本的なフロントエンド画面                              |
| 3        | ダッシュボード表示の作り込み   | 3-5日    | 評価結果の整形表示 (記号, 理由, スコア), レイアウト調整, 結果の累積表示機能 (オプション), (任意) UIライブラリ導入・適用                                                                              | 見やすい評価結果表示ダッシュボード                                     |
| 4        | エクスポート機能の実装         | 3-4日    | BE: `/export` API (配列受け取り), CSV/MD生成ロジック<br>FE: エクスポートUI (形式選択, ボタン), API呼び出し, ファイルダウンロード処理                                                                 | CSV/Markdownエクスポート機能                                           |
| 5        | 全体調整とテスト             | 2-3日    | 結合テスト, UI/UX微調整, エラーハンドリング強化, README作成                                                                                                                                        | テスト済みアプリケーション, 基本的なドキュメント                         |
| 6        | デプロイ (任意)              | 1-2日    | デプロイ環境選定・設定 (Heroku, Vercel/Netlify, Fly.io等), デプロイ実行, 本番環境テスト                                                                                                          | デプロイされたアプリケーション                                           |
| **合計** |                                | **14-22日** | *(注: 日数は目安であり、個人のスキルやタスクの難易度により変動します)*                                                                                                                              |                                                                      |

## 5. タスク詳細（WBS簡易版 - フェーズ1, 2の例）

| ID      | フェーズ | タスク内容                                  | 担当   | 見積(人日) | 依存タスク | 備考                                       |
| :------ | :------- | :------------------------------------------ | :----- | :--------- | :--------- | :----------------------------------------- |
| **BE-01** | 1        | Flask/FastAPI プロジェクト初期設定          | Dev    | 0.5        | -          | 仮想環境, 基本構成                         |
| BE-02   | 1        | Gemini APIクライアント設定・認証           | Dev    | 0.5        | BE-01      | `google-generativeai`, APIキー設定(.env) |
| BE-03   | 1        | `/evaluate` APIエンドポイント作成 (雛形)   | Dev    | 0.5        | BE-01      | リクエスト(テキスト)受け取り、仮レスポンス   |
| BE-04   | 1        | Gemini API呼び出し実装                      | Dev    | 1.0        | BE-02, BE-03 | プロンプト作成、JSON応答期待             |
| BE-05   | 1        | Gemini応答(JSON)のパースと検証            | Dev    | 0.5        | BE-04      | スキーマに基づきデータ抽出                 |
| BE-06   | 1        | スコア計算ロジック実装                      | Dev    | 0.5        | BE-05      | 重み付けルール適用                       |
| BE-07   | 1        | `/evaluate` API レスポンス生成 (完成版)    | Dev    | 0.5        | BE-06      | `EvaluationResult` JSONオブジェクト返却    |
| BE-08   | 1        | 単体テスト (スコア計算、Geminiモック利用)  | Dev    | 0.5        | BE-06      | `pytest` 等                                |
| **FE-01** | 2        | React/Vue プロジェクト初期設定             | Dev    | 0.5        | -          | `create-react-app`/`vite` 等             |
| FE-02   | 2        | テキスト入力コンポーネント作成              | Dev    | 0.5        | FE-01      | `textarea`, 状態管理                     |
| FE-03   | 2        | 「解析」ボタンとイベントハンドラ            | Dev    | 0.5        | FE-02      | クリック時に処理開始                     |
| FE-04   | 2        | `/evaluate` API 呼び出し実装 (axios)       | Dev    | 0.5        | FE-03, BE-07 | バックエンドAPIへリクエスト送信            |
| FE-05   | 2        | レスポンス表示コンポーネント (簡易)         | Dev    | 0.5        | FE-04      | 受け取ったJSONを整形せず表示でも可         |
| FE-06   | 2        | 基本的なエラー表示実装                    | Dev    | 0.5        | FE-04      | APIエラー等をユーザーに通知              |
| ...     | ...      | (以下、フェーズ3〜6のタスクも同様に細分化) | ...    | ...        | ...        |                                            |

## 6. リスク管理

| リスク項目                                 | 発生可能性 | 影響度 | 対応策・軽減策                                                                                                                               |
| :----------------------------------------- | :--------- | :----- | :------------------------------------------------------------------------------------------------------------------------------------------- |
| Gemini APIの応答が不安定/期待通りでない     | 中         | 高     | プロンプトの改善・調整、リトライ処理の実装、エラーハンドリング強化、他のモデル（GPT等）への切り替え可能性検討                                      |
| Gemini APIの利用料金が想定を超える          | 中         | 中     | 利用状況のモニタリング、API呼び出し頻度の最適化、より安価なモデルの検討、予算アラート設定                                                        |
| Gemini APIの仕様変更による影響            | 低         | 高     | Google Cloudのリリースノートを注視、APIクライアントライブラリのバージョン管理、変更に追従するための改修期間をバッファとして持つ                      |
| プロンプトの調整に時間がかかる              | 高         | 中     | 初期段階で複数のプロンプトパターンを試し、効果的なものを採用。継続的な改善を前提とする。                                                           |
| 入力テキストからの情報抽出精度が低い        | 中         | 中     | Geminiに構造化データ（JSON）での出力を強く指示するプロンプトにする。場合によってはバックエンドでの簡単な前処理（正規表現等）も検討。               |
| フロントエンドでの状態管理が複雑化する    | 中         | 中     | 評価結果の累積表示を行う場合、適切な状態管理ライブラリ（Zustand, Redux Toolkit等）を導入する。初期は単純な上書き方式で複雑さを回避する。           |
| 開発スケジュールの遅延                    | 中         | 中     | タスク見積もりの精度向上、進捗の定期的な確認、技術的な課題の早期発見と対応、必要に応じてスコープ調整。                                             |
| セキュリティリスク（APIキー漏洩など）       | 低         | 高     | `.env`ファイルをGit管理外にする。環境変数経由でのみAPIキーを読み込む。コードレビューでのチェック。                                                  |

## 7. テスト計画

*   **単体テスト:**
    *   バックエンド: スコア計算ロジック、Gemini API連携モックを使ったサービスクラス、APIリクエスト/レスポンス処理 (`pytest`)
    *   フロントエンド: 各コンポーネントの表示・動作 (`Jest`, `React Testing Library` / `Vue Test Utils`)
*   **結合テスト:**
    *   フロントエンド ⇔ バックエンド: 実際のAPI通信を伴うシナリオテスト（テキスト入力→解析→表示→エクスポート）
    *   バックエンド ⇔ Gemini API: 実際のGemini API（開発用キー、少量データ）を使ったテスト（応答形式、品質確認）
*   **手動テスト / 受け入れテスト:**
    *   要件定義書の機能要件、非機能要件が満たされているかを確認。
    *   様々な候補者情報テキストパターンでの評価テスト。
    *   UI/UXの確認、ブラウザ互換性テスト（対象ブラウザを定義）。
    *   エクスポートされたファイルの形式・内容確認。

## 8. リリース計画（デプロイする場合）

*   **リリース手順:**
    1.  最終テスト（ステージング環境があればそこで）
    2.  本番環境へのデプロイ（CI/CDがあれば自動化）
    3.  本番環境での動作確認（スモークテスト）
*   **リリース判定基準:**
    *   主要な機能要件がすべて満たされていること。
    *   致命的なバグが存在しないこと。
    *   パフォーマンス、セキュリティ要件が基準を満たしていること。
    *   テスト計画に基づいたテストが完了し、許容できない問題が残っていないこと。